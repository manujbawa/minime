#!/usr/bin/env node

/**
 * Test script to validate AI integration
 * Tests: LLM Service, Embedding Service, Learning Pipeline with LLM integration
 */

import winston from 'winston';
import { DatabaseService } from './services/database-service.js';
import { EmbeddingService } from './services/embedding-service.js';
import { LLMService } from './services/llm-service.js';
import { LearningPipeline } from './services/learning-pipeline.js';

// Configure logger
const logger = winston.createLogger({
    level: 'info',
    format: winston.format.combine(
        winston.format.timestamp(),
        winston.format.simple()
    ),
    transports: [
        new winston.transports.Console()
    ]
});

async function testAIIntegration() {
    let dbService, embeddingService, llmService, learningPipeline;
    
    try {
        logger.info('ðŸ§ª Starting AI Integration Tests...\n');

        // Test 1: Database Service
        logger.info('1ï¸âƒ£ Testing Database Service...');
        dbService = new DatabaseService(logger, {
            host: process.env.POSTGRES_HOST || 'localhost',
            port: process.env.POSTGRES_PORT || 5432,
            database: process.env.POSTGRES_DB || 'minime_memories',
            user: process.env.POSTGRES_USER || 'minime',
            password: process.env.POSTGRES_PASSWORD || 'minime_password'
        });
        
        await dbService.initialize();
        logger.info('âœ… Database Service initialized successfully\n');

        // Test 2: Embedding Service  
        logger.info('2ï¸âƒ£ Testing Embedding Service...');
        embeddingService = new EmbeddingService(logger, dbService);
        
        // Check default model
        const defaultModel = await embeddingService.getDefaultModel();
        logger.info(`   Default embedding model: ${defaultModel}`);
        
        // Test health check
        const embeddingHealth = await embeddingService.healthCheck();
        logger.info(`   Embedding service health: ${embeddingHealth.status}`);
        
        if (embeddingHealth.status === 'healthy') {
            logger.info('âœ… Embedding Service working correctly\n');
        } else {
            logger.warn(`âš ï¸ Embedding Service degraded: ${embeddingHealth.message}\n`);
        }

        // Test 3: LLM Service
        logger.info('3ï¸âƒ£ Testing LLM Service...');
        llmService = new LLMService(logger, dbService);
        
        // Test health check
        const llmHealth = await llmService.healthCheck();
        logger.info(`   LLM service health: ${llmHealth.healthy ? 'healthy' : 'unhealthy'}`);
        
        if (llmHealth.healthy) {
            logger.info(`   Ollama version: ${llmHealth.ollamaVersion}`);
            logger.info(`   Default model: ${llmHealth.defaultModel}`);
            logger.info('âœ… LLM Service working correctly\n');
        } else {
            logger.warn(`âš ï¸ LLM Service unavailable: ${llmHealth.error}\n`);
        }

        // Test 4: Learning Pipeline with LLM Integration
        logger.info('4ï¸âƒ£ Testing Learning Pipeline with LLM Integration...');
        learningPipeline = new LearningPipeline(logger, dbService, embeddingService, llmService);
        
        await learningPipeline.initialize();
        logger.info('âœ… Learning Pipeline initialized with LLM integration\n');

        // Test 5: Test pattern outcome correlation methods
        logger.info('5ï¸âƒ£ Testing Outcome Correlation System...');
        
        // Check if outcome correlation methods exist
        const methods = [
            'analyzePatternOutcomeCorrelations',
            'recordPatternOutcome', 
            'triggerOutcomeAnalysis',
            'performLLMOutcomeCorrelation'
        ];
        
        for (const method of methods) {
            if (typeof learningPipeline[method] === 'function') {
                logger.info(`   âœ… Method ${method} exists`);
            } else {
                logger.error(`   âŒ Method ${method} missing`);
            }
        }
        
        logger.info('âœ… Outcome Correlation System methods available\n');

        // Test 6: Integration with database schema
        logger.info('6ï¸âƒ£ Testing Database Schema Integration...');
        
        // Check if required tables exist
        const tables = ['pattern_outcomes', 'pattern_correlations', 'llm_analysis_cache'];
        for (const table of tables) {
            try {
                const result = await dbService.query(`SELECT COUNT(*) FROM ${table} LIMIT 1`);
                logger.info(`   âœ… Table ${table} exists and accessible`);
            } catch (error) {
                logger.warn(`   âš ï¸ Table ${table} not accessible: ${error.message}`);
            }
        }
        
        logger.info('âœ… Database schema integration tested\n');

        // Test 7: Test embedding generation with new model
        if (embeddingHealth.status === 'healthy') {
            logger.info('7ï¸âƒ£ Testing Embedding Generation...');
            try {
                const testEmbedding = await embeddingService.generateEmbedding(
                    "This is a test to validate the new mxbai-embed-large model works correctly."
                );
                logger.info(`   âœ… Generated embedding with ${testEmbedding.length} dimensions`);
                logger.info(`   Expected 1024 dimensions: ${testEmbedding.length === 1024 ? 'PASS' : 'FAIL'}\n`);
            } catch (error) {
                logger.error(`   âŒ Embedding generation failed: ${error.message}\n`);
            }
        }

        // Test 8: Test LLM analysis (if available)
        if (llmHealth.healthy) {
            logger.info('8ï¸âƒ£ Testing LLM Analysis...');
            try {
                const testAnalysis = await llmService.generateAnalysis(
                    "Analyze this simple coding pattern: using async/await for handling asynchronous operations in JavaScript.",
                    { maxTokens: 200 },
                    'patternAnalysis'
                );
                logger.info(`   âœ… LLM analysis generated: ${testAnalysis.content.substring(0, 100)}...`);
                logger.info(`   Confidence: ${testAnalysis.confidence}\n`);
            } catch (error) {
                logger.error(`   âŒ LLM analysis failed: ${error.message}\n`);
            }
        }

        logger.info('ðŸŽ‰ AI Integration Tests Completed Successfully!');
        logger.info('\nSummary:');
        logger.info('- âœ… Database Service: Working');
        logger.info(`- ${embeddingHealth.status === 'healthy' ? 'âœ…' : 'âš ï¸'} Embedding Service: ${embeddingHealth.status}`);
        logger.info(`- ${llmHealth.healthy ? 'âœ…' : 'âš ï¸'} LLM Service: ${llmHealth.healthy ? 'healthy' : 'unhealthy'}`);
        logger.info('- âœ… Learning Pipeline: Integrated with LLM');
        logger.info('- âœ… Outcome Correlation: Methods available');
        logger.info('- âœ… Database Schema: Compatible');

    } catch (error) {
        logger.error('âŒ AI Integration Test Failed:', error.message);
        process.exit(1);
    } finally {
        // Cleanup
        if (dbService) {
            await dbService.close();
        }
    }
}

// Run the test
testAIIntegration().catch(error => {
    console.error('Test runner failed:', error);
    process.exit(1);
});